# Serve an LLM with multiple GPUs in GKE samples

[![Open in Cloud Shell](https://gstatic.com/cloudssh/images/open-btn.svg)](https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/GoogleCloudPlatform/kubernetes-engine-samples&cloudshell_tutorial=README.md&cloudshell_workspace=ai-ml/llm-multiple-gpus)

This example shows how to serve an LLM with multiple GPUs using
[Google Kubernetes Engine](https://cloud.google.com/kubernetes-engine).

Visit https://cloud.google.com/kubernetes-engine/docs/tutorials/serve-multiple-gpu
to follow the tutorial.
